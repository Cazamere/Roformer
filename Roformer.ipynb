{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cazamere/Roformer/blob/main/Roformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ku4JvtNSDWSm"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxZeYr-UDWSo"
      },
      "source": [
        "Data Sourcing and Processing\n",
        "============================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kowZuR4nDWSp"
      },
      "outputs": [],
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.datasets import multi30k, Multi30k\n",
        "from typing import Iterable, List\n",
        "\n",
        "# We need to modify the URLs for the dataset since the links to the original dataset are broken\n",
        "multi30k.URL[\"train\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/training.tar.gz\"\n",
        "multi30k.URL[\"valid\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/validation.tar.gz\"\n",
        "\n",
        "SRC_LANGUAGE = 'en'\n",
        "TGT_LANGUAGE = 'de'\n",
        "\n",
        "token_transform = {}\n",
        "vocab_transform = {}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Once this cell is done, restart kernel to reload dependencies\n",
        "!pip install -U torchdata\n",
        "!pip install -U spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download de_core_news_sm"
      ],
      "metadata": {
        "id": "KZibgmEGDgAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install portalocker==2.8.2"
      ],
      "metadata": {
        "id": "v0f6qwYoEHIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3Xtb8GRnDWSp"
      },
      "outputs": [],
      "source": [
        "token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='de_core_news_sm')\n",
        "token_transform[TGT_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')\n",
        "\n",
        "# helper function to yield list of tokens\n",
        "def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n",
        "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
        "\n",
        "    for data_sample in data_iter:\n",
        "        yield token_transform[language](data_sample[language_index[language]])\n",
        "\n",
        "# Define special symbols and indices\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
        "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
        "\n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "    # Training data Iterator\n",
        "    train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "    # Create torchtext's Vocab object\n",
        "    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train_iter, ln),\n",
        "                                                    min_freq=1,\n",
        "                                                    specials=special_symbols,\n",
        "                                                    special_first=True)\n",
        "\n",
        "# Set ``UNK_IDX`` as the default index. This index is returned when the token is not found.\n",
        "# If not set, it throws ``RuntimeError`` when the queried token is not found in the Vocabulary.\n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "  vocab_transform[ln].set_default_index(UNK_IDX)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMTSsKnEDWSp"
      },
      "source": [
        "Transformer\n",
        "================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OgoidqsTDWSq"
      },
      "outputs": [],
      "source": [
        "# Transformer model\n",
        "\n",
        "from torch import Tensor\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import Transformer\n",
        "import math\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self,\n",
        "                 emb_size: int,\n",
        "                 dropout: float,\n",
        "                 maxlen: int = 5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
        "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
        "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
        "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
        "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
        "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('pos_embedding', pos_embedding)\n",
        "\n",
        "    def forward(self, token_embedding: Tensor):\n",
        "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
        "\n",
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size: int, emb_size):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
        "        self.emb_size = emb_size\n",
        "\n",
        "    def forward(self, tokens: Tensor):\n",
        "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
        "\n",
        "class Seq2SeqTransformer(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_encoder_layers: int,\n",
        "                 num_decoder_layers: int,\n",
        "                 emb_size: int,\n",
        "                 nhead: int,\n",
        "                 src_vocab_size: int,\n",
        "                 tgt_vocab_size: int,\n",
        "                 dim_feedforward: int = 512,\n",
        "                 dropout: float = 0.1):\n",
        "        super(Seq2SeqTransformer, self).__init__()\n",
        "        self.transformer = Transformer(d_model=emb_size,\n",
        "                                       nhead=nhead,\n",
        "                                       num_encoder_layers=num_encoder_layers,\n",
        "                                       num_decoder_layers=num_decoder_layers,\n",
        "                                       dim_feedforward=dim_feedforward,\n",
        "                                       dropout=dropout)\n",
        "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
        "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
        "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
        "        self.positional_encoding = PositionalEncoding(\n",
        "            emb_size, dropout=dropout)\n",
        "\n",
        "    def forward(self,\n",
        "                src: Tensor,\n",
        "                trg: Tensor,\n",
        "                src_mask: Tensor,\n",
        "                tgt_mask: Tensor,\n",
        "                src_padding_mask: Tensor,\n",
        "                tgt_padding_mask: Tensor,\n",
        "                memory_key_padding_mask: Tensor):\n",
        "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
        "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
        "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n",
        "                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
        "        return self.generator(outs)\n",
        "\n",
        "    def encode(self, src: Tensor, src_mask: Tensor):\n",
        "        return self.transformer.encoder(self.positional_encoding(\n",
        "                            self.src_tok_emb(src)), src_mask)\n",
        "\n",
        "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
        "        return self.transformer.decoder(self.positional_encoding(\n",
        "                          self.tgt_tok_emb(tgt)), memory,\n",
        "                          tgt_mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Roformer"
      ],
      "metadata": {
        "id": "Ne4RTYCvuDjj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Roformer\n",
        "\n",
        "class RotaryEmbedding(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        inv_freq = 1.0 / (10000 ** (torch.arange(0, dim, 2).float() / dim)) # theta\n",
        "        self.register_buffer('inv_freq', inv_freq)\n",
        "\n",
        "    def forward(self, pos): # pos -> p\n",
        "        sinusoid_inp = torch.outer(pos.float().squeeze(0), self.inv_freq) # m * theta\n",
        "        return torch.cat((sinusoid_inp.sin(), sinusoid_inp.cos()), dim=-1) # combine sin and cosine frequencies\n",
        "\n",
        "def apply_rotary_pos_emb(x, sincos):\n",
        "    sin, cos = torch.split(sincos, sincos.shape[-1] // 2, dim=1) # split sin and cosine frequencies\n",
        "    sin = sin.unsqueeze(1)\n",
        "    cos = cos.unsqueeze(1)\n",
        "    x1, x2 = x[..., :x.size(-1) // 2], x[..., x.size(-1) // 2:]\n",
        "    return torch.cat([x1 * cos + x2 * sin, x2 * cos - x1 * sin], dim=-1) # rotate input vectors\n",
        "\n",
        "# Wrapper around nn.MultiheadAttention\n",
        "class RotaryAttention(nn.Module):\n",
        "    def __init__(self, emb_size, nhead, dropout=0.0):\n",
        "        super().__init__()\n",
        "        self.multihead_attn = nn.MultiheadAttention(emb_size, nhead, dropout=dropout)\n",
        "        self.rotary_emb = RotaryEmbedding(emb_size)\n",
        "\n",
        "    def forward(self, query, key, value, attn_mask=None, key_padding_mask=None):\n",
        "        query_seq_len, key_seq_len, batch_size = query.size(0), key.size(0), query.size(1)\n",
        "        query_pos = torch.arange(query_seq_len, device=query.device).unsqueeze(0) # Generates a range of position indices from 0 to query_seq_len-1\n",
        "        query_pos_emb = self.rotary_emb(query_pos)\n",
        "\n",
        "        key_pos = torch.arange(key_seq_len, device=key.device).unsqueeze(0) # Generates a range of position indices from 0 to key_seq_len-1\n",
        "        key_pos_emb = self.rotary_emb(key_pos)\n",
        "\n",
        "        # Apply rotary embeddings to queries and keys\n",
        "        query, key = apply_rotary_pos_emb(query, query_pos_emb), apply_rotary_pos_emb(key, key_pos_emb)\n",
        "\n",
        "        # Proceed with MHA\n",
        "        return self.multihead_attn(query, key, value, attn_mask=attn_mask, key_padding_mask=key_padding_mask)\n",
        "\n",
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size: int, emb_size: int):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
        "        self.emb_size = emb_size\n",
        "\n",
        "    def forward(self, tokens: Tensor):\n",
        "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
        "\n",
        "class RoformerEncoderLayer(nn.Module):\n",
        "    def __init__(self, emb_size: int, nhead: int, dim_feedforward: int, dropout: float):\n",
        "        super(RoformerEncoderLayer, self).__init__()\n",
        "        self.self_attn = RotaryAttention(emb_size, nhead, dropout=dropout)\n",
        "        self.linear1 = nn.Linear(emb_size, dim_feedforward)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear2 = nn.Linear(dim_feedforward, emb_size)\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(emb_size)\n",
        "        self.norm2 = nn.LayerNorm(emb_size)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "    def forward(self, src: Tensor, src_mask: Tensor, src_key_padding_mask: Tensor):\n",
        "        src2 = self.self_attn(src, src, src, attn_mask=src_mask,\n",
        "                              key_padding_mask=src_key_padding_mask)[0]\n",
        "        src = src + self.dropout1(src2)\n",
        "        src = self.norm1(src)\n",
        "        src2 = self.linear2(self.dropout(self.activation(self.linear1(src))))\n",
        "        src = src + self.dropout2(src2)\n",
        "        src = self.norm2(src)\n",
        "        return src\n",
        "\n",
        "class RoformerDecoderLayer(nn.Module):\n",
        "    def __init__(self, emb_size: int, nhead: int, dim_feedforward: int, dropout: float):\n",
        "        super(RoformerDecoderLayer, self).__init__()\n",
        "        self.self_attn = RotaryAttention(emb_size, nhead, dropout=dropout)\n",
        "        self.multihead_attn = RotaryAttention(emb_size, nhead, dropout=dropout)\n",
        "        self.linear1 = nn.Linear(emb_size, dim_feedforward)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear2 = nn.Linear(dim_feedforward, emb_size)\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(emb_size)\n",
        "        self.norm2 = nn.LayerNorm(emb_size)\n",
        "        self.norm3 = nn.LayerNorm(emb_size)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.dropout3 = nn.Dropout(dropout)\n",
        "\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "    def forward(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor, memory_mask: Tensor,\n",
        "                tgt_key_padding_mask: Tensor, memory_key_padding_mask: Tensor):\n",
        "        tgt2 = self.self_attn(tgt, tgt, tgt, attn_mask=tgt_mask,\n",
        "                              key_padding_mask=tgt_key_padding_mask)[0]\n",
        "        tgt = tgt + self.dropout1(tgt2)\n",
        "        tgt = self.norm1(tgt)\n",
        "        tgt2 = self.multihead_attn(tgt, memory, memory, attn_mask=memory_mask,\n",
        "                                   key_padding_mask=memory_key_padding_mask)[0]\n",
        "        tgt = tgt + self.dropout2(tgt2)\n",
        "        tgt = self.norm2(tgt)\n",
        "        tgt2 = self.linear2(self.dropout(self.activation(self.linear1(tgt))))\n",
        "        tgt = tgt + self.dropout3(tgt2)\n",
        "        tgt = self.norm3(tgt)\n",
        "        return tgt\n",
        "\n",
        "class RoformerEncoder(nn.Module):\n",
        "    def __init__(self, emb_size, nhead, num_layers, dim_feedforward, dropout):\n",
        "        super(RoformerEncoder, self).__init__()\n",
        "        self.layers = nn.ModuleList([RoformerEncoderLayer(emb_size, nhead, dim_feedforward, dropout) for _ in range(num_layers)])\n",
        "        self.norm = nn.LayerNorm(emb_size)\n",
        "\n",
        "    def forward(self, src, mask, src_key_padding_mask):\n",
        "        for layer in self.layers:\n",
        "            src = layer(src, src_mask=mask, src_key_padding_mask=src_key_padding_mask)\n",
        "        src = self.norm(src)\n",
        "        return src\n",
        "\n",
        "class RoformerDecoder(nn.Module):\n",
        "    def __init__(self, emb_size, nhead, num_layers, dim_feedforward, dropout):\n",
        "        super(RoformerDecoder, self).__init__()\n",
        "        self.layers = nn.ModuleList([RoformerDecoderLayer(emb_size, nhead, dim_feedforward, dropout) for _ in range(num_layers)])\n",
        "        self.norm = nn.LayerNorm(emb_size)\n",
        "\n",
        "    def forward(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask):\n",
        "        for layer in self.layers:\n",
        "            tgt = layer(tgt, memory, tgt_mask=tgt_mask, memory_mask=memory_mask,\n",
        "                        tgt_key_padding_mask=tgt_key_padding_mask, memory_key_padding_mask=memory_key_padding_mask)\n",
        "        tgt = self.norm(tgt)\n",
        "        return tgt\n",
        "\n",
        "class Roformer(nn.Module):\n",
        "    def __init__(self, num_encoder_layers, num_decoder_layers, emb_size, nhead, src_vocab_size, tgt_vocab_size, dim_feedforward=512, dropout=0.1):\n",
        "        super(Roformer, self).__init__()\n",
        "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
        "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.encoder = RoformerEncoder(emb_size, nhead, num_encoder_layers, dim_feedforward, dropout)\n",
        "        self.decoder = RoformerDecoder(emb_size, nhead, num_decoder_layers, dim_feedforward, dropout)\n",
        "\n",
        "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
        "\n",
        "    def forward(self, src, tgt, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, memory_key_padding_mask):\n",
        "        src_emb = self.dropout(self.src_tok_emb(src))\n",
        "        tgt_emb = self.dropout(self.tgt_tok_emb(tgt))\n",
        "\n",
        "        memory = self.encoder(src_emb, src_mask, src_padding_mask)\n",
        "        outs = self.decoder(tgt_emb, memory, tgt_mask, None, tgt_padding_mask, memory_key_padding_mask)\n",
        "        return self.generator(outs)\n",
        "\n",
        "    def encode(self, src, src_mask):\n",
        "        src_emb = self.dropout(self.src_tok_emb(src))\n",
        "        return self.encoder(src_emb, src_mask, None)\n",
        "\n",
        "    def decode(self, tgt, memory, tgt_mask):\n",
        "        tgt_emb = self.dropout(self.tgt_tok_emb(tgt))\n",
        "        return self.decoder(tgt_emb, memory, tgt_mask, None, None, None)"
      ],
      "metadata": {
        "id": "9WN6ABe0Fdf2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attention Masks"
      ],
      "metadata": {
        "id": "-aXm-S4kuHvP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jRz2-zfRDWSq"
      },
      "outputs": [],
      "source": [
        "def generate_square_subsequent_mask(sz):\n",
        "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
        "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "    return mask\n",
        "\n",
        "\n",
        "def create_mask(src, tgt):\n",
        "    src_seq_len = src.shape[0]\n",
        "    tgt_seq_len = tgt.shape[0]\n",
        "\n",
        "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
        "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
        "\n",
        "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
        "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
        "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtvwxHx7DWSq"
      },
      "source": [
        "Collation\n",
        "=========\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Dng_yDF0DWSq"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# helper function to club together sequential operations\n",
        "def sequential_transforms(*transforms):\n",
        "    def func(txt_input):\n",
        "        for transform in transforms:\n",
        "            txt_input = transform(txt_input)\n",
        "        return txt_input\n",
        "    return func\n",
        "\n",
        "# function to add BOS/EOS and create tensor for input sequence indices\n",
        "def tensor_transform(token_ids: List[int]):\n",
        "    return torch.cat((torch.tensor([BOS_IDX]),\n",
        "                      torch.tensor(token_ids),\n",
        "                      torch.tensor([EOS_IDX])))\n",
        "\n",
        "# ``src`` and ``tgt`` language text transforms to convert raw strings into tensors indices\n",
        "text_transform = {}\n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "    text_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n",
        "                                               vocab_transform[ln], #Numericalization\n",
        "                                               tensor_transform) # Add BOS/EOS and create tensor\n",
        "\n",
        "\n",
        "# function to collate data samples into batch tensors\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = [], []\n",
        "    for src_sample, tgt_sample in batch:\n",
        "        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n",
        "        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
        "\n",
        "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
        "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
        "    return src_batch, tgt_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6eNksvsDWSr"
      },
      "source": [
        "# Training & Evaluate Loops\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "KTLa3JB1DWSr"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def train_epoch(model, optimizer, BATCH_SIZE, loss_fn):\n",
        "    model.train()\n",
        "    losses = 0\n",
        "    train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "    train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "\n",
        "    for src, tgt in train_dataloader:\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "\n",
        "        tgt_input = tgt[:-1, :]\n",
        "\n",
        "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "\n",
        "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        tgt_out = tgt[1:, :]\n",
        "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        losses += loss.item()\n",
        "\n",
        "    return losses / len(list(train_dataloader))\n",
        "\n",
        "def evaluate_epoch(model, BATCH_SIZE, loss_fn):\n",
        "    model.eval()\n",
        "    losses = 0\n",
        "\n",
        "    val_iter = Multi30k(split='valid', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "    val_dataloader = DataLoader(val_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "\n",
        "    for src, tgt in val_dataloader:\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "\n",
        "        tgt_input = tgt[:-1, :]\n",
        "\n",
        "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "\n",
        "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
        "\n",
        "        tgt_out = tgt[1:, :]\n",
        "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "        losses += loss.item()\n",
        "\n",
        "    return losses / len(list(val_dataloader))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "eRW0MgZ6snCx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "pYYj56Y1DWSr"
      },
      "outputs": [],
      "source": [
        "from timeit import default_timer as timer\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torch.optim.lr_scheduler import _LRScheduler\n",
        "import sys\n",
        "\n",
        "def train(model):\n",
        "\n",
        "  torch.manual_seed(0)\n",
        "\n",
        "  SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
        "  TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
        "  EMB_SIZE = 512\n",
        "  NHEAD = 4\n",
        "  FFN_HID_DIM = 512\n",
        "  BATCH_SIZE = 128\n",
        "  NUM_ENCODER_LAYERS = 2\n",
        "  NUM_DECODER_LAYERS = 2\n",
        "\n",
        "  if model == 'transformer':\n",
        "    transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
        "                                  NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
        "  elif model == 'roformer':\n",
        "    transformer = Roformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
        "                                  NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
        "  else:\n",
        "    sys.exit('Model not supported')\n",
        "\n",
        "  for p in transformer.parameters():\n",
        "      if p.dim() > 1:\n",
        "          nn.init.xavier_uniform_(p)\n",
        "\n",
        "  transformer = transformer.to(DEVICE)\n",
        "\n",
        "  loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX, label_smoothing=0.1)\n",
        "\n",
        "  optimizer = torch.optim.Adam(transformer.parameters(), lr=1e-4, betas=(0.9, 0.98), eps=1e-9)\n",
        "\n",
        "  NUM_EPOCHS = 10\n",
        "\n",
        "  best_val_loss = float('inf')\n",
        "  patience = 0\n",
        "\n",
        "  patience_max = 5\n",
        "\n",
        "  for epoch in range(1, NUM_EPOCHS+1):\n",
        "      start_time = timer()\n",
        "      train_loss = train_epoch(transformer, optimizer, BATCH_SIZE, loss_fn)\n",
        "      end_time = timer()\n",
        "      val_loss = evaluate_epoch(transformer, BATCH_SIZE, loss_fn)\n",
        "\n",
        "\n",
        "      if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(transformer, 'model.pt')\n",
        "        patience = 0\n",
        "\n",
        "      patience += 1\n",
        "\n",
        "      if patience == patience_max:\n",
        "        break\n",
        "\n",
        "      print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decode"
      ],
      "metadata": {
        "id": "37XugQOUw7Rg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to generate output sequence using greedy algorithm\n",
        "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
        "    src = src.to(DEVICE)\n",
        "    src_mask = src_mask.to(DEVICE)\n",
        "\n",
        "    memory = model.encode(src, src_mask)\n",
        "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
        "    for i in range(max_len-1):\n",
        "        memory = memory.to(DEVICE)\n",
        "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
        "                    .type(torch.bool)).to(DEVICE)\n",
        "        out = model.decode(ys, memory, tgt_mask)\n",
        "        out = out.transpose(0, 1)\n",
        "        prob = model.generator(out[:, -1])\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "        next_word = next_word.item()\n",
        "\n",
        "        ys = torch.cat([ys,\n",
        "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
        "        if next_word == EOS_IDX:\n",
        "            break\n",
        "    return ys\n",
        "\n",
        "# function to generate output sequence using beam search algorithm\n",
        "def beam_search_decode(model, src, src_mask, max_len, start_symbol, beam_size, alpha):\n",
        "\n",
        "    src = src.to(DEVICE)\n",
        "    src_mask = src_mask.to(DEVICE)\n",
        "\n",
        "    memory = model.encode(src, src_mask).to(DEVICE)\n",
        "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
        "\n",
        "    active_beams = [(0, [start_symbol])]  # Each beam is a tuple(score, token_ids)\n",
        "\n",
        "    for step in range(max_len):\n",
        "        new_beams = []\n",
        "        for score, token_ids in active_beams:\n",
        "            tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
        "                        .type(torch.bool)).to(DEVICE)\n",
        "            out = model.decode(ys, memory, tgt_mask)\n",
        "            out = out.transpose(0, 1)\n",
        "            probabilities = model.generator(out[:, -1])\n",
        "\n",
        "            top_probs, top_tokens = torch.topk(probabilities, beam_size) # Get top beam_size next tokens and their log probabilities\n",
        "            top_probs, top_tokens = top_probs.squeeze(0), top_tokens.squeeze(0)\n",
        "\n",
        "            # Add new hypotheses to new_beams\n",
        "            for i in range(beam_size):\n",
        "                next_score = score + top_probs[i].item()\n",
        "                next_token_ids = token_ids + [top_tokens[i].item()]\n",
        "                new_beams.append((next_score, next_token_ids))\n",
        "\n",
        "                if next_token_ids[-1] == EOS_IDX:  # Early stopping\n",
        "                    return next_token_ids\n",
        "\n",
        "        # Keep top beam_size hypotheses\n",
        "        active_beams = sorted(new_beams, key=lambda x: x[0] / (len(x[1]) ** alpha), reverse=True)[:beam_size]\n",
        "\n",
        "    # Return hypothesis with the highest score\n",
        "    return max(active_beams, key=lambda x: x[0] / (len(x[1]) ** alpha))[1]"
      ],
      "metadata": {
        "id": "yuzzqWrAF_4a"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.metrics import bleu_score\n",
        "\n",
        "def translate_greedy(model: torch.nn.Module, src):\n",
        "    model.eval()\n",
        "    num_tokens = src.shape[0]\n",
        "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
        "    tgt_tokens = greedy_decode(\n",
        "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
        "\n",
        "    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\").split(\" \")[1:-1]\n",
        "\n",
        "def translate_beam_search(model: torch.nn.Module, src, beam_size=4, alpha=0.6):\n",
        "    model.eval()\n",
        "    num_tokens = src.shape[0]\n",
        "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
        "    tgt_tokens = beam_search_decode(\n",
        "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX, beam_size=beam_size, alpha=alpha)\n",
        "\n",
        "    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(tgt_tokens)).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\").split(\" \")[1:-1]\n",
        "\n",
        "def evaluate_test(model, mode):\n",
        "    model.eval()\n",
        "    losses = 0\n",
        "    candidate_corpus = []\n",
        "    reference_corpus = []\n",
        "\n",
        "    test_iter = Multi30k(split='valid', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE)) # The test split in PyTorch is broken, so evaluating on valid split\n",
        "    test_dataloader = DataLoader(test_iter, batch_size=1, collate_fn=collate_fn)  # Set batch_size to 1 for simplicity\n",
        "    for src, tgt in test_dataloader:\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "\n",
        "        # Translate the source sentence\n",
        "        if mode == 'greedy': # Greedy decoder\n",
        "          translated_sentence = translate_greedy(model, src)\n",
        "        elif mode == 'beam': # Beam search decoder\n",
        "          translated_sentence = translate_beam_search(model, src, beam_size=2, alpha=0.6) # Doesn't work great, likely due to small training set\n",
        "        else:\n",
        "            sys.exit('Mode not supported')\n",
        "\n",
        "        candidate_corpus.append(translated_sentence)\n",
        "\n",
        "        # Prepare the reference sentence\n",
        "        tgt_sent = [tok for tok in tgt.view(-1).cpu().numpy()]\n",
        "        tgt_sent = \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(tgt_sent)).replace(\"<bos>\", \"\").replace(\"<eos>\", \".\").split(\" \")[1:]\n",
        "        reference_corpus.append([tgt_sent])\n",
        "\n",
        "\n",
        "    # Calculate BLEU score\n",
        "    bleu = bleu_score(candidate_corpus, reference_corpus, max_n=4, weights = [0.25]*4)\n",
        "    return bleu"
      ],
      "metadata": {
        "id": "HScOnShQx9r6"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run"
      ],
      "metadata": {
        "id": "yabG2fgrw-65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_type = 'roformer' # 'roformer' or 'transformer'\n",
        "train(model_type)"
      ],
      "metadata": {
        "id": "Asw14VSAwhVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_transformer = torch.load('model.pt')"
      ],
      "metadata": {
        "id": "l28pmkyY4nok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bleu = evaluate_test(best_transformer, 'greedy')"
      ],
      "metadata": {
        "id": "L0mZjXF1yAXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Transformer BLEU: {bleu*100:.2f}')"
      ],
      "metadata": {
        "id": "8y_-CUtUNAUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7b6Ka1Mubs1B"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "jtvwxHx7DWSq"
      ],
      "machine_shape": "hm",
      "gpuType": "L4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}